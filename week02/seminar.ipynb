{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum about Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://github.com/markovka17/dl-start-pack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.wandb.com/\n",
    "\n",
    "Create free account and login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login <token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init wandb\n",
    "config = {\n",
    "    'a': 10,\n",
    "    'b': 20,\n",
    "    'batch_size': 8\n",
    "}\n",
    "\n",
    "wandb.init(project=\"axial-transformer\",\n",
    "           config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ")\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'accuracy': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'accuracy': 0.95})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Audio\": wandb.Audio('../week01/audio.wav', sample_rate=22050, caption='Example')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.save('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Gaussian Noise\n",
    "    2) Time Stretching\n",
    "    3) Pitch Shifting\n",
    "    4) Volume\n",
    "    5) Impulse Response\n",
    "        - https://www.acousticalsurfaces.com/acoustic_IOI/reverberation.htm\n",
    "        - https://www.sonic-shield.com/echo-vs-reverberation\n",
    "        - https://en.wikipedia.org/wiki/Convolution_reverb\n",
    "        - https://danielpovey.com/files/2017_icassp_reverberation.pdf\n",
    "    6) Noising with diff audio\n",
    "        - https://medium.com/analytics-vidhya/adding-noise-to-audio-clips-5d8cee24ccb8\n",
    "        - https://arxiv.org/pdf/1808.00563.pdf (3.1)\n",
    "    7) SpecAug (Time/Freq masking, Cutout)\n",
    "        - https://arxiv.org/pdf/1904.08779.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "from IPython import display as display_\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = torchaudio.load('../week01/audio.wav')\n",
    "wav.squeeze_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz(wav):\n",
    "    figsize(20, 5)\n",
    "    plot(wav)\n",
    "    plt.show()\n",
    "\n",
    "    display_.display(display_.Audio(wav, rate=22050, normalize=False))\n",
    "\n",
    "viz(wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = distributions.Normal(0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_2 = wav + noiser.sample(wav.size())\n",
    "wav_2.clamp_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Time Stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for spectrograms\n",
    "torchaudio.transforms.TimeStretch\n",
    "\n",
    "# audio -> spec -> TimeStretch -> GriffinLim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_3 = librosa.effects.time_stretch(wav.numpy(), 0.7)\n",
    "wav_3 = torch.from_numpy(wav_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Pitch Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_4 = librosa.effects.pitch_shift(wav.numpy(), 22050, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voler = torchaudio.transforms.Vol(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_5 = voler(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Impulse Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir, sr = torchaudio.load('/Users/markaa/MITIR/mitir_16kHz/h001_Bedroom_65txts.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rir.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_.Audio(rir, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def simulate(audio: torch.Tensor, rir: torch.Tensor):\n",
    "    left_pad = right_pad = rir.shape[-1] - 1\n",
    "    \n",
    "    # Since torch.conv do cross-correlation (not convolution) we need to flip kernel\n",
    "    flipped_rir = rir.squeeze().flip(0)\n",
    "\n",
    "    audio = F.pad(audio, [left_pad, right_pad]).view(1, 1, -1)\n",
    "    convolved_audio = torch.conv1d(audio, flipped_rir.view(1, 1, -1)) \\\n",
    "        .squeeze()\n",
    "    \n",
    "    # peak normalization\n",
    "    if convolved_audio.abs().max() > 1:\n",
    "        convolved_audio /= convolved_audio.abs().max()\n",
    "\n",
    "    return convolved_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_6 = simulate(wav, rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz(wav_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + Noising with diff audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = librosa.ex('trumpet')\n",
    "y, sr = librosa.load(filename)\n",
    "\n",
    "noise = y\n",
    "\n",
    "viz(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noize_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "noize_energy = torch.norm(torch.from_numpy(noise))\n",
    "audio_energy = torch.norm(wav)\n",
    "\n",
    "alpha = (audio_energy / noize_energy) * torch.pow(10, -noize_level / 20)\n",
    "\n",
    "# sample sub wave (but not now)\n",
    "wav = wav[:noise.shape[0]]\n",
    "\n",
    "wav_7 = wav + alpha * torch.from_numpy(noise)\n",
    "wav_7.clamp_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(wav_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# + SpecAug (Time/Freq masking, Cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogramer = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=22050,\n",
    "    n_fft=1024,\n",
    "    win_length=1024,\n",
    "    hop_length=256,\n",
    "    f_min=0,\n",
    "    f_max=8000,\n",
    "    n_mels=80,\n",
    ")\n",
    "\n",
    "mel_spectrogram = mel_spectrogramer(wav)\n",
    "log_mel = torch.log(mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(log_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_masker = torchaudio.transforms.FrequencyMasking(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = mel_spectrogramer(wav)\n",
    "log_mel = torch.log(mel_spectrogram)\n",
    "imshow(freq_masker(log_mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_masker = torchaudio.transforms.TimeMasking(100, True)\n",
    "log_mel = torch.log(mel_spectrogram)\n",
    "imshow(time_masker(log_mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
